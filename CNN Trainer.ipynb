{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Convolutional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport h5py\nimport librosa\nimport itertools\nfrom copy import copy\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom collections import OrderedDict\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport warnings  \nwith warnings.catch_warnings():  \n    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Add\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import PReLU\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG = '../input/gtzan-dataset-music-genre-classification/Data/images_original'\n#IMG = './dataset/'\nimg_dataset = []\ngenre_target = []\ngenres = {}\nclasses = []\ni = 0\nfor root, dirs, files in os.walk(IMG):\n    for name in files:\n        filename = os.path.join(root, name)\n        img_dataset.append(filename)\n        genre = filename.split('/')[-2]\n        genre_target.append(genre)\n        \n        if(genre not in genres):\n            classes.append(genre)\n            genres[genre] = i\n            i+=1\n\nimg = cv2.imread(img_dataset[0],1)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['metal',\n 'country',\n 'reggae',\n 'hiphop',\n 'blues',\n 'rock',\n 'jazz',\n 'classical',\n 'pop',\n 'disco']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_borders(img,x1=35,x2=252,y1=54,y2=389):\n    cropped = img[x1:x2,y1:y2]\n    return cropped\n\ndef get_y():\n    '''Convierte los generos en un array de targets y'''\n    y = []\n    for genre in genre_target:\n        n = genres[genre]\n        y.append(n)\n    return np.array(y)\n\ndef get_x(shape=[999,217,335], flag=1):\n    x = np.empty(shape, np.uint8)\n    for i in range(len(img_dataset)):\n        img = cv2.imread(img_dataset[i],flag)\n        img = crop_borders(img)\n        x[i] = img\n    return np.array(x)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(img_dataset[0])\nimg = crop_borders(img)\n\nimg.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(217, 335, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = get_x(shape=[999,img.shape[0], img.shape[1], img.shape[2]]) #Imagenes en color, RGB -> 3 canales\ny = get_y()\n\nm = len(y)\nnum_labels = 10 #estilos de musica diferente\n\nprint(X.shape, y.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"(999, 217, 335, 3) (999,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n\ny = to_categorical(y)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"(799, 217, 335, 3) (200, 217, 335, 3) (799, 10) (200, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_block(x, n_filters, pool_size=(2, 2)):\n    x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding='same')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=pool_size, strides=pool_size)(x)\n    x = Dropout(0.25)(x)\n    return x","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Definition\ndef create_model(input_shape, num_genres):\n    inpt = Input(shape=input_shape)\n    x = conv_block(inpt, 16)\n    x = conv_block(x, 32)\n    x = conv_block(x, 64)\n    x = conv_block(x, 128)\n    x = conv_block(x, 256)\n    \n    # Classifier with MLP (MultiLayerPerceptron)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n    x = Dropout(0.25)(x)\n    predictions = Dense(num_genres,activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n    \n    model = Model(inputs=inpt, outputs=predictions)\n    return model","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model(X_train[0].shape, num_labels)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 217, 335, 3)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 217, 335, 16)      448       \n_________________________________________________________________\nactivation (Activation)      (None, 217, 335, 16)      0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 108, 167, 16)      0         \n_________________________________________________________________\ndropout (Dropout)            (None, 108, 167, 16)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 108, 167, 32)      4640      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 108, 167, 32)      0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 54, 83, 32)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 54, 83, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 54, 83, 64)        18496     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 54, 83, 64)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 27, 41, 64)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 27, 41, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 27, 41, 128)       73856     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 27, 41, 128)       0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 13, 20, 128)       0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 13, 20, 128)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 13, 20, 256)       295168    \n_________________________________________________________________\nactivation_4 (Activation)    (None, 13, 20, 256)       0         \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 6, 10, 256)        0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 6, 10, 256)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 15360)             0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 15360)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               7864832   \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 8,262,570\nTrainable params: 8,262,570\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=tf.keras.losses.categorical_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduceLROnPlat = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.95,\n    patience=3,\n    verbose=1,\n    mode='min',\n    min_delta=0.0001,\n    cooldown=2,\n    min_lr=1e-5\n)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(\n    X_train,y_train,\n    validation_data=(X_test, y_test),\n    epochs=150,\n    verbose=1,\n    callbacks=[reduceLROnPlat])","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/150\n25/25 [==============================] - 1s 57ms/step - loss: 54.1054 - accuracy: 0.1176 - val_loss: 22.9072 - val_accuracy: 0.0900 - lr: 0.0010\nEpoch 2/150\n25/25 [==============================] - 1s 41ms/step - loss: 22.3260 - accuracy: 0.1114 - val_loss: 21.4878 - val_accuracy: 0.1550 - lr: 0.0010\nEpoch 3/150\n25/25 [==============================] - 1s 37ms/step - loss: 20.6566 - accuracy: 0.1314 - val_loss: 19.7664 - val_accuracy: 0.2350 - lr: 0.0010\nEpoch 4/150\n25/25 [==============================] - 1s 36ms/step - loss: 19.0115 - accuracy: 0.1314 - val_loss: 18.2436 - val_accuracy: 0.2350 - lr: 0.0010\nEpoch 5/150\n25/25 [==============================] - 1s 37ms/step - loss: 17.5496 - accuracy: 0.1840 - val_loss: 16.8770 - val_accuracy: 0.3000 - lr: 0.0010\nEpoch 6/150\n25/25 [==============================] - 1s 35ms/step - loss: 16.1844 - accuracy: 0.2128 - val_loss: 15.6263 - val_accuracy: 0.2650 - lr: 0.0010\nEpoch 7/150\n25/25 [==============================] - 1s 37ms/step - loss: 15.0754 - accuracy: 0.2140 - val_loss: 14.6988 - val_accuracy: 0.1900 - lr: 0.0010\nEpoch 8/150\n25/25 [==============================] - 1s 37ms/step - loss: 14.0778 - accuracy: 0.2303 - val_loss: 13.6322 - val_accuracy: 0.3100 - lr: 0.0010\nEpoch 9/150\n25/25 [==============================] - 1s 37ms/step - loss: 13.1550 - accuracy: 0.2390 - val_loss: 12.8020 - val_accuracy: 0.3050 - lr: 0.0010\nEpoch 10/150\n25/25 [==============================] - 1s 36ms/step - loss: 12.2797 - accuracy: 0.2428 - val_loss: 11.9528 - val_accuracy: 0.3400 - lr: 0.0010\nEpoch 11/150\n25/25 [==============================] - 1s 35ms/step - loss: 11.4691 - accuracy: 0.2728 - val_loss: 11.2176 - val_accuracy: 0.3400 - lr: 0.0010\nEpoch 12/150\n25/25 [==============================] - 1s 35ms/step - loss: 10.7788 - accuracy: 0.2791 - val_loss: 10.5210 - val_accuracy: 0.3750 - lr: 0.0010\nEpoch 13/150\n25/25 [==============================] - 1s 37ms/step - loss: 10.1386 - accuracy: 0.3004 - val_loss: 9.9804 - val_accuracy: 0.2900 - lr: 0.0010\nEpoch 14/150\n25/25 [==============================] - 1s 37ms/step - loss: 9.5873 - accuracy: 0.3317 - val_loss: 9.4855 - val_accuracy: 0.3500 - lr: 0.0010\nEpoch 15/150\n25/25 [==============================] - 1s 36ms/step - loss: 9.0163 - accuracy: 0.3442 - val_loss: 8.8947 - val_accuracy: 0.4350 - lr: 0.0010\nEpoch 16/150\n25/25 [==============================] - 1s 36ms/step - loss: 8.5903 - accuracy: 0.3467 - val_loss: 8.4416 - val_accuracy: 0.3250 - lr: 0.0010\nEpoch 17/150\n25/25 [==============================] - 1s 36ms/step - loss: 8.0566 - accuracy: 0.3980 - val_loss: 7.9438 - val_accuracy: 0.3950 - lr: 0.0010\nEpoch 18/150\n25/25 [==============================] - 1s 36ms/step - loss: 7.6380 - accuracy: 0.3942 - val_loss: 7.5843 - val_accuracy: 0.3900 - lr: 0.0010\nEpoch 19/150\n25/25 [==============================] - 1s 36ms/step - loss: 7.2968 - accuracy: 0.3980 - val_loss: 7.2476 - val_accuracy: 0.4100 - lr: 0.0010\nEpoch 20/150\n25/25 [==============================] - 1s 37ms/step - loss: 6.9785 - accuracy: 0.4180 - val_loss: 7.0793 - val_accuracy: 0.3050 - lr: 0.0010\nEpoch 21/150\n25/25 [==============================] - 1s 37ms/step - loss: 6.6107 - accuracy: 0.4418 - val_loss: 6.5364 - val_accuracy: 0.4800 - lr: 0.0010\nEpoch 22/150\n25/25 [==============================] - 1s 35ms/step - loss: 6.2828 - accuracy: 0.4668 - val_loss: 6.2307 - val_accuracy: 0.4750 - lr: 0.0010\nEpoch 23/150\n25/25 [==============================] - 1s 36ms/step - loss: 5.9690 - accuracy: 0.4743 - val_loss: 6.1130 - val_accuracy: 0.3900 - lr: 0.0010\nEpoch 24/150\n25/25 [==============================] - 1s 36ms/step - loss: 5.7375 - accuracy: 0.4568 - val_loss: 5.7505 - val_accuracy: 0.5450 - lr: 0.0010\nEpoch 25/150\n25/25 [==============================] - 1s 36ms/step - loss: 5.4745 - accuracy: 0.4631 - val_loss: 5.4570 - val_accuracy: 0.5800 - lr: 0.0010\nEpoch 26/150\n25/25 [==============================] - 1s 36ms/step - loss: 5.2989 - accuracy: 0.4731 - val_loss: 5.5024 - val_accuracy: 0.3150 - lr: 0.0010\nEpoch 27/150\n25/25 [==============================] - 1s 36ms/step - loss: 5.0472 - accuracy: 0.4881 - val_loss: 5.1875 - val_accuracy: 0.4250 - lr: 0.0010\nEpoch 28/150\n25/25 [==============================] - 1s 36ms/step - loss: 4.8874 - accuracy: 0.4919 - val_loss: 4.9207 - val_accuracy: 0.5250 - lr: 0.0010\nEpoch 29/150\n25/25 [==============================] - 1s 36ms/step - loss: 4.6443 - accuracy: 0.5069 - val_loss: 4.6183 - val_accuracy: 0.5850 - lr: 0.0010\nEpoch 30/150\n25/25 [==============================] - 1s 35ms/step - loss: 4.4619 - accuracy: 0.5181 - val_loss: 4.5628 - val_accuracy: 0.5600 - lr: 0.0010\nEpoch 31/150\n25/25 [==============================] - 1s 36ms/step - loss: 4.2389 - accuracy: 0.5607 - val_loss: 4.3768 - val_accuracy: 0.5650 - lr: 0.0010\nEpoch 32/150\n25/25 [==============================] - 1s 38ms/step - loss: 4.1576 - accuracy: 0.5632 - val_loss: 4.3345 - val_accuracy: 0.4950 - lr: 0.0010\nEpoch 33/150\n25/25 [==============================] - 1s 37ms/step - loss: 4.0562 - accuracy: 0.5695 - val_loss: 4.2415 - val_accuracy: 0.5600 - lr: 0.0010\nEpoch 34/150\n25/25 [==============================] - 1s 36ms/step - loss: 3.8249 - accuracy: 0.5882 - val_loss: 3.9435 - val_accuracy: 0.5550 - lr: 0.0010\nEpoch 35/150\n25/25 [==============================] - 1s 35ms/step - loss: 3.7520 - accuracy: 0.5645 - val_loss: 3.9810 - val_accuracy: 0.5450 - lr: 0.0010\nEpoch 36/150\n25/25 [==============================] - 1s 36ms/step - loss: 3.7612 - accuracy: 0.5682 - val_loss: 4.0935 - val_accuracy: 0.4000 - lr: 0.0010\nEpoch 37/150\n25/25 [==============================] - ETA: 0s - loss: 3.6993 - accuracy: 0.5682\nEpoch 00037: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n25/25 [==============================] - 1s 35ms/step - loss: 3.6993 - accuracy: 0.5682 - val_loss: 4.1432 - val_accuracy: 0.4100 - lr: 0.0010\nEpoch 38/150\n25/25 [==============================] - 1s 37ms/step - loss: 3.6872 - accuracy: 0.5832 - val_loss: 3.7479 - val_accuracy: 0.5950 - lr: 9.5000e-04\nEpoch 39/150\n25/25 [==============================] - 1s 35ms/step - loss: 3.4239 - accuracy: 0.5932 - val_loss: 3.5415 - val_accuracy: 0.5650 - lr: 9.5000e-04\nEpoch 40/150\n25/25 [==============================] - 1s 36ms/step - loss: 3.2496 - accuracy: 0.6258 - val_loss: 3.5587 - val_accuracy: 0.5750 - lr: 9.5000e-04\nEpoch 41/150\n25/25 [==============================] - 1s 36ms/step - loss: 3.2758 - accuracy: 0.6120 - val_loss: 3.9336 - val_accuracy: 0.3550 - lr: 9.5000e-04\nEpoch 42/150\n25/25 [==============================] - 1s 36ms/step - loss: 3.1550 - accuracy: 0.6496 - val_loss: 3.3064 - val_accuracy: 0.5700 - lr: 9.5000e-04\nEpoch 43/150\n25/25 [==============================] - 1s 35ms/step - loss: 3.0457 - accuracy: 0.6633 - val_loss: 3.4880 - val_accuracy: 0.4950 - lr: 9.5000e-04\nEpoch 44/150\n25/25 [==============================] - 1s 38ms/step - loss: 3.0057 - accuracy: 0.6546 - val_loss: 3.3209 - val_accuracy: 0.5500 - lr: 9.5000e-04\nEpoch 45/150\n25/25 [==============================] - 1s 36ms/step - loss: 2.9753 - accuracy: 0.6383 - val_loss: 3.2783 - val_accuracy: 0.5500 - lr: 9.5000e-04\nEpoch 46/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.8719 - accuracy: 0.6596 - val_loss: 3.1101 - val_accuracy: 0.6050 - lr: 9.5000e-04\nEpoch 47/150\n25/25 [==============================] - 1s 36ms/step - loss: 2.9225 - accuracy: 0.6721 - val_loss: 3.1528 - val_accuracy: 0.6250 - lr: 9.5000e-04\nEpoch 48/150\n25/25 [==============================] - 1s 36ms/step - loss: 2.8702 - accuracy: 0.6421 - val_loss: 3.0098 - val_accuracy: 0.6400 - lr: 9.5000e-04\nEpoch 49/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.8868 - accuracy: 0.6796 - val_loss: 3.0822 - val_accuracy: 0.6200 - lr: 9.5000e-04\nEpoch 50/150\n25/25 [==============================] - 1s 36ms/step - loss: 2.7441 - accuracy: 0.6633 - val_loss: 3.0828 - val_accuracy: 0.5950 - lr: 9.5000e-04\nEpoch 51/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.6971 - accuracy: 0.7196 - val_loss: 2.9763 - val_accuracy: 0.6550 - lr: 9.5000e-04\nEpoch 52/150\n","name":"stdout"},{"output_type":"stream","text":"25/25 [==============================] - 1s 35ms/step - loss: 2.6236 - accuracy: 0.7234 - val_loss: 3.1848 - val_accuracy: 0.5100 - lr: 9.5000e-04\nEpoch 53/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.5818 - accuracy: 0.7447 - val_loss: 2.8882 - val_accuracy: 0.6400 - lr: 9.5000e-04\nEpoch 54/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.5720 - accuracy: 0.7096 - val_loss: 2.9883 - val_accuracy: 0.6350 - lr: 9.5000e-04\nEpoch 55/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.5840 - accuracy: 0.7034 - val_loss: 2.8630 - val_accuracy: 0.6850 - lr: 9.5000e-04\nEpoch 56/150\n25/25 [==============================] - 1s 37ms/step - loss: 2.5974 - accuracy: 0.7059 - val_loss: 2.9859 - val_accuracy: 0.6000 - lr: 9.5000e-04\nEpoch 57/150\n25/25 [==============================] - 1s 36ms/step - loss: 2.5345 - accuracy: 0.7297 - val_loss: 2.8805 - val_accuracy: 0.6400 - lr: 9.5000e-04\nEpoch 58/150\n25/25 [==============================] - ETA: 0s - loss: 2.4912 - accuracy: 0.7384\nEpoch 00058: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n25/25 [==============================] - 1s 36ms/step - loss: 2.4912 - accuracy: 0.7384 - val_loss: 2.8828 - val_accuracy: 0.6500 - lr: 9.5000e-04\nEpoch 59/150\n25/25 [==============================] - 1s 36ms/step - loss: 2.4754 - accuracy: 0.7359 - val_loss: 2.9572 - val_accuracy: 0.5750 - lr: 9.0250e-04\nEpoch 60/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.3661 - accuracy: 0.7597 - val_loss: 2.6844 - val_accuracy: 0.7300 - lr: 9.0250e-04\nEpoch 61/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.2671 - accuracy: 0.7897 - val_loss: 2.8077 - val_accuracy: 0.6250 - lr: 9.0250e-04\nEpoch 62/150\n25/25 [==============================] - 1s 35ms/step - loss: 2.4606 - accuracy: 0.7247 - val_loss: 2.7890 - val_accuracy: 0.6550 - lr: 9.0250e-04\nEpoch 63/150\n13/25 [==============>...............] - ETA: 0s - loss: 2.3333 - accuracy: 0.7861","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\nprint(\"test_loss = {:.3f} and test_acc = {:.3f}\".format(test_loss, test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\n\nplt.subplot(1,2,1)\nplt.plot(hist.history['accuracy'], label='train')\nplt.plot(hist.history['val_accuracy'], label='validation')\nplt.title('Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='validation')\nplt.title('Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.argmax(model.predict(X_test), axis = 1)\ny_orig = np.argmax(y_test, axis = 1)\ncm = confusion_matrix(preds, y_orig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#keys = OrderedDict(sorted(genres.items(), key=lambda t: t[1])).keys()\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, classes, normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model\nmodel.save('custom_cnn_2d_color_final.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Prueba de canciones de fuera del dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir('../input/test-songs-gtzan/images')\nsongs = [ '../input/test-songs-gtzan/images/'+img for img in files if img.split('.')[-1] == 'png']\nsongs = np.sort(songs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for song in songs:\n    if(song[-7:-4] != \"cut\" and song[-7:-4] != \"BnW\"): #quitamos imagines no cortadas y en blanco y negro\n        img = cv2.imread(song, 1)\n        img = img.reshape(-1,217,335,3)\n        pred = np.argmax(model.predict(img), axis = 1)\n        print(song[33:-4],\"-->\",classes[pred[0]],'\\n')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}