{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import cv2 #pip install opencv-python\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from scipy.optimize import minimize\n",
    "import librosa                    \n",
    "import librosa.display\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = './data/images_original/'\n",
    "#IMG = './dataset/'\n",
    "img_dataset = []\n",
    "genre_target = []\n",
    "genres = {}\n",
    "i = 0\n",
    "for root, dirs, files in os.walk(IMG):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        img_dataset.append(filename)\n",
    "        genre = filename.split('\\\\')[0].split('/')[-1]\n",
    "        genre_target.append(genre)\n",
    "        \n",
    "        if(genre not in genres):\n",
    "            genres[genre] = i\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n"
     ]
    }
   ],
   "source": [
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(img_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(genre_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_borders(img,x1=35,x2=252,y1=54,y2=389):\n",
    "    cropped = img[x1:x2,y1:y2]\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(): \n",
    "    '''Convierte los generos en un array de targets y'''\n",
    "    y = []\n",
    "    for genre in genre_target:\n",
    "        #OneHot encoding?\n",
    "        n = genres[genre]\n",
    "        y.append(n)\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, m, num_labels):\n",
    "    '''one hot encoding'''\n",
    "    y_onehot = np.zeros((m, num_labels))  # 5000 x 10\n",
    "    for i in range(m):\n",
    "        y_onehot[i][y[i]] = 1\n",
    "    return y_onehot\n",
    "\n",
    "def get_x(shape=[999,217*335], flag=0):\n",
    "    '''Covierte las imagenes en arrays'''\n",
    "    x = np.empty(shape, np.uint8)\n",
    "    for i in range(len(img_dataset)):\n",
    "        img = cv2.imread(img_dataset[i],flag)\n",
    "        img = crop_borders(img)\n",
    "        x[i] = img.ravel()\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "def pesosAleatorios(L_in, L_out):\n",
    "    ini_epsilon = 0.12\n",
    "    theta = np.random.rand(L_out, 1 + L_in) * (2*ini_epsilon) - ini_epsilon \n",
    "    return theta\n",
    "\n",
    "def forward_propagation(X, theta1, theta2):\n",
    "    '''Funcion de propagaci√≥n hacia delante para red neuronal de 3 capas'''\n",
    "    m = X.shape[0]\n",
    "    a1 = np.hstack([np.ones([m, 1]), X]) \n",
    "    z2 = np.dot(a1, theta1.T)\n",
    "    a2 = np.hstack([np.ones([m, 1]), sigmoid(z2)])\n",
    "    z3 = np.dot(a2, theta2.T)\n",
    "    h = sigmoid(z3)\n",
    "    return a1, z2, a2, z3, h\n",
    "\n",
    "def backprop(params_rn, num_entradas, num_ocultas, num_etiquetas, X, y, reg=0):\n",
    "    '''Funcion de back-propagation para red neuronal de 3 capas''' \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Desplegamos los paramas_rn en la matrices Theta\n",
    "    theta1 = np.reshape(params_rn[:num_ocultas * (num_entradas + 1)],\n",
    "                       (num_ocultas, (num_entradas + 1)))\n",
    "    theta2 = np.reshape(params_rn[num_ocultas * (num_entradas + 1):],\n",
    "                       (num_etiquetas, (num_ocultas + 1)))\n",
    "    \n",
    "    # Aplicamos forward-propagation para calcular la salidas de cada capa\n",
    "    a1, z2, a2, z3, h = forward_propagation(X, theta1, theta2)\n",
    "    \n",
    "    # Calculo del coste\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        a = np.dot(-y[i,:], np.log(h[i,:]))\n",
    "        b = np.dot((1-y[i,:]), np.log(1-h[i,:]))\n",
    "        cost += np.sum(a - b)\n",
    "        \n",
    "    cost = cost/m\n",
    "    \n",
    "    # Regularizacion del coste\n",
    "    cost += reg/(2*m) * (np.sum(theta1[:, 1:]**2) + np.sum(theta2[:, 1:]**2))\n",
    "    \n",
    "    # Back-propagation\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    \n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]\n",
    "        a2t = a2[t,:]\n",
    "        ht = h[t,:]\n",
    "        yt = y[t]\n",
    "        \n",
    "        d3 = ht - yt\n",
    "        d2 = np.dot(theta2.T, d3) * (a2t * (1 - a2t))\n",
    "        \n",
    "        delta1 += np.dot(d2[1:, np.newaxis], a1t[np.newaxis, :])\n",
    "        delta2 += np.dot(d3[:, np.newaxis], a2t[np.newaxis, :])\n",
    "        \n",
    "    # Calculo del gradiente\n",
    "    D1 = delta1 / m\n",
    "    D2 = delta2 / m\n",
    "    \n",
    "    # Regularizacion del gradiente\n",
    "    D1[:, 1:] = D1[:, 1:] + (reg * theta1[:, 1:]) / m\n",
    "    D2[:, 1:] = D2[:, 1:] + (reg * theta2[:, 1:]) / m\n",
    "    \n",
    "    gradient = np.concatenate((np.ravel(D1), np.ravel(D2)))\n",
    "    \n",
    "    return cost, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 72695) (999,) (999, 10)\n"
     ]
    }
   ],
   "source": [
    "X = get_x()\n",
    "y = get_y()\n",
    "y_onehot = one_hot(y, len(y), len(genres))\n",
    "\n",
    "print(X.shape, y.shape, y_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "\n",
    "def train(X, y, num_labels, hidden_size, reg, iters):\n",
    "    num_entradas = X.shape[1]\n",
    "    num_ocultas = hidden_size\n",
    "    num_etiquetas = num_labels\n",
    "\n",
    "    theta1 = pesosAleatorios(num_entradas, num_ocultas)\n",
    "    theta2 = pesosAleatorios(num_ocultas, num_etiquetas)\n",
    "    params = np.concatenate((np.ravel(theta1), np.ravel(theta2)))\n",
    "\n",
    "    fmin = opt.minimize(fun=backprop, x0=params, \n",
    "                 args=(num_entradas, num_ocultas, num_etiquetas, X, y, reg),\n",
    "                 method='TNC', jac=True, options={'maxiter' : iters})\n",
    "\n",
    "    theta1 = np.reshape(fmin.x[:num_ocultas * (num_entradas + 1)],\n",
    "                       (num_ocultas, (num_entradas + 1)))\n",
    "    theta2 = np.reshape(fmin.x[num_ocultas * (num_entradas + 1):],\n",
    "                       (num_etiquetas, (num_ocultas + 1)))\n",
    "\n",
    "    a1, z2, a2, z2, h = forward_propagation(X, theta1, theta2)\n",
    "\n",
    "    predictions = np.argmax(h, axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = train(X, y_onehot, num_labels=len(genres), hidden_size=25, reg=1, iters=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 897\n",
      "Numero de aciertos: 102\n",
      "\n",
      "Porcentaje de aciertos:  10.21021021021021\n"
     ]
    }
   ],
   "source": [
    "fallos =  np.where([predictions != y])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 814\n",
      "Numero de aciertos: 185\n",
      "\n",
      "Porcentaje de aciertos:  18.51851851851852\n"
     ]
    }
   ],
   "source": [
    "predictions = train(X, y_onehot, num_labels=len(genres), hidden_size=25, reg=0.1, iters=70)\n",
    "\n",
    "fallos =  np.where([predictions != y])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 861\n",
      "Numero de aciertos: 138\n",
      "\n",
      "Porcentaje de aciertos:  13.813813813813812\n"
     ]
    }
   ],
   "source": [
    "predictions = train(X, y_onehot, num_labels=len(genres), hidden_size=25, reg=0.1, iters=110)\n",
    "\n",
    "fallos =  np.where([predictions != y])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 809\n",
      "Numero de aciertos: 190\n",
      "\n",
      "Porcentaje de aciertos:  19.01901901901902\n"
     ]
    }
   ],
   "source": [
    "predictions = train(X, y_onehot, num_labels=len(genres), hidden_size=50, reg=0.1, iters=70)\n",
    "\n",
    "fallos =  np.where([predictions != y])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 816\n",
      "Numero de aciertos: 183\n",
      "\n",
      "Porcentaje de aciertos:  18.31831831831832\n"
     ]
    }
   ],
   "source": [
    "predictions = train(X, y_onehot, num_labels=len(genres), hidden_size=100, reg=0.1, iters=100)\n",
    "\n",
    "fallos =  np.where([predictions != y])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 824\n",
      "Numero de aciertos: 175\n",
      "\n",
      "Porcentaje de aciertos:  17.51751751751752\n"
     ]
    }
   ],
   "source": [
    "predictions = train(X, y_onehot, num_labels=len(genres), hidden_size=100, reg=1, iters=100)\n",
    "\n",
    "fallos =  np.where([predictions != y])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 72695) (749, 72695)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test, = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "print(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = one_hot(y_train, len(y_train), len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "\n",
    "def train(X_train, y_train, X_test, num_labels, hidden_size, reg, iters):\n",
    "    num_entradas = X_train.shape[1]\n",
    "    num_ocultas = hidden_size\n",
    "    num_etiquetas = num_labels\n",
    "\n",
    "    theta1 = pesosAleatorios(num_entradas, num_ocultas)\n",
    "    theta2 = pesosAleatorios(num_ocultas, num_etiquetas)\n",
    "    params = np.concatenate((np.ravel(theta1), np.ravel(theta2)))\n",
    "\n",
    "    fmin = opt.minimize(fun=backprop, x0=params, \n",
    "                 args=(num_entradas, num_ocultas, num_etiquetas, X_train, y_train, reg),\n",
    "                 method='TNC', jac=True, options={'maxiter' : iters})\n",
    "\n",
    "    theta1 = np.reshape(fmin.x[:num_ocultas * (num_entradas + 1)],\n",
    "                       (num_ocultas, (num_entradas + 1)))\n",
    "    theta2 = np.reshape(fmin.x[num_ocultas * (num_entradas + 1):],\n",
    "                       (num_etiquetas, (num_ocultas + 1)))\n",
    "\n",
    "    a1, z2, a2, z2, h = forward_propagation(X_test, theta1, theta2)\n",
    "\n",
    "    predictions = np.argmax(h, axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 208\n",
      "Numero de aciertos: 42\n",
      "\n",
      "Porcentaje de aciertos:  16.8\n"
     ]
    }
   ],
   "source": [
    "predictions = train(X_train, y_train_onehot, X_test, num_labels=len(genres), hidden_size=25, reg=0.1, iters=70)\n",
    "\n",
    "fallos =  np.where([predictions != y_test])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y_test])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y_test)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, REG= 0\n",
      "\tNumero de fallos: 204\n",
      "\tNumero de aciertos: 46\n",
      "\n",
      "\tPorcentaje de aciertos:  18.4\n",
      "Training, REG= 0.1\n",
      "\tNumero de fallos: 224\n",
      "\tNumero de aciertos: 26\n",
      "\n",
      "\tPorcentaje de aciertos:  10.4\n",
      "Training, REG= 0.3\n",
      "\tNumero de fallos: 207\n",
      "\tNumero de aciertos: 43\n",
      "\n",
      "\tPorcentaje de aciertos:  17.2\n",
      "Training, REG= 0.5\n",
      "\tNumero de fallos: 222\n",
      "\tNumero de aciertos: 28\n",
      "\n",
      "\tPorcentaje de aciertos:  11.200000000000001\n",
      "Training, REG= 1\n",
      "\tNumero de fallos: 223\n",
      "\tNumero de aciertos: 27\n",
      "\n",
      "\tPorcentaje de aciertos:  10.8\n",
      "Training, REG= 3\n",
      "\tNumero de fallos: 218\n",
      "\tNumero de aciertos: 32\n",
      "\n",
      "\tPorcentaje de aciertos:  12.8\n"
     ]
    }
   ],
   "source": [
    "def multiple_train(X_train, y_train, X_test, num_labels, hidden_size, reg_params, iters):\n",
    "    for reg in reg_params:\n",
    "        print(\"Training, REG=\", reg)\n",
    "        predictions = train(X_train, y_train, X_test, num_labels, hidden_size, reg, iters)\n",
    "        \n",
    "        fallos =  np.where([predictions != y_test])[1]\n",
    "        print('\\tNumero de fallos:', len(fallos))\n",
    "\n",
    "        aciertos = np.where([predictions == y_test])[1]\n",
    "        print('\\tNumero de aciertos:', len(aciertos))\n",
    "\n",
    "        accuracy = 100 * np.mean(predictions == y_test)\n",
    "        print(\"\\n\\tPorcentaje de aciertos: \", accuracy)\n",
    "        \n",
    "reg_params = [0, 0.1, 0.3, 0.5, 1, 3]\n",
    "multiple_train(X_train, y_train_onehot, X_test, num_labels=len(genres), hidden_size=25, reg_params=reg_params, iters=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de fallos: 842\n",
      "Numero de aciertos: 157\n",
      "\n",
      "Porcentaje de aciertos:  15.715715715715717\n"
     ]
    }
   ],
   "source": [
    "predictions = train(X, y_onehot, X, num_labels=len(genres), hidden_size=25, reg=0, iters=70)\n",
    "\n",
    "fallos =  np.where([predictions != y])[1]\n",
    "print('Numero de fallos:', len(fallos))\n",
    "\n",
    "aciertos = np.where([predictions == y])[1]\n",
    "print('Numero de aciertos:', len(aciertos))\n",
    "\n",
    "accuracy = 100 * np.mean(predictions == y)\n",
    "print(\"\\nPorcentaje de aciertos: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(50, 50), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=200, alpha=0.001, activation='relu', random_state=42)\n",
    "\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10013351134846461"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP layers: (25,), alpha: 0.0001...\n",
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25,), alpha: 0.01...\n",
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25,), alpha: 0.1...\n",
      "\t Train accuracy:  0.09879839786381843\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25,), alpha: 0.3...\n",
      "\t Train accuracy:  0.09879839786381843\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25,), alpha: 1...\n",
      "\t Train accuracy:  0.09879839786381843\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25, 25), alpha: 0.0001...\n",
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25, 25), alpha: 0.01...\n",
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25, 25), alpha: 0.1...\n",
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (25, 25), alpha: 0.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Train accuracy:  0.16955941255006676\n",
      "\t Test accuracy:  0.156\n",
      "Training MLP layers: (25, 25), alpha: 1...\n",
      "\t Train accuracy:  0.09879839786381843\n",
      "\t Test accuracy:  0.096\n",
      "Training MLP layers: (25, 25, 25), alpha: 0.0001...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.384\n",
      "Training MLP layers: (25, 25, 25), alpha: 0.01...\n",
      "\t Train accuracy:  0.9946595460614153\n",
      "\t Test accuracy:  0.356\n",
      "Training MLP layers: (25, 25, 25), alpha: 0.1...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.356\n",
      "Training MLP layers: (25, 25, 25), alpha: 0.3...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.356\n",
      "Training MLP layers: (25, 25, 25), alpha: 1...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.372\n",
      "Training MLP layers: (50,), alpha: 0.0001...\n",
      "\t Train accuracy:  0.102803738317757\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50,), alpha: 0.01...\n",
      "\t Train accuracy:  0.102803738317757\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50,), alpha: 0.1...\n",
      "\t Train accuracy:  0.10146862483311081\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50,), alpha: 0.3...\n",
      "\t Train accuracy:  0.10146862483311081\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50,), alpha: 1...\n",
      "\t Train accuracy:  0.10146862483311081\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50, 50), alpha: 0.0001...\n",
      "\t Train accuracy:  0.1041388518024032\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50, 50), alpha: 0.01...\n",
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50, 50), alpha: 0.1...\n",
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50, 50), alpha: 0.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50, 50), alpha: 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Train accuracy:  0.10013351134846461\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (50, 50, 50), alpha: 0.0001...\n",
      "\t Train accuracy:  0.9946595460614153\n",
      "\t Test accuracy:  0.28\n",
      "Training MLP layers: (50, 50, 50), alpha: 0.01...\n",
      "\t Train accuracy:  0.9599465954606141\n",
      "\t Test accuracy:  0.312\n",
      "Training MLP layers: (50, 50, 50), alpha: 0.1...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.288\n",
      "Training MLP layers: (50, 50, 50), alpha: 0.3...\n",
      "\t Train accuracy:  0.9345794392523364\n",
      "\t Test accuracy:  0.276\n",
      "Training MLP layers: (50, 50, 50), alpha: 1...\n",
      "\t Train accuracy:  0.10146862483311081\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (100,), alpha: 0.0001...\n",
      "\t Train accuracy:  0.2656875834445928\n",
      "\t Test accuracy:  0.188\n",
      "Training MLP layers: (100,), alpha: 0.01...\n",
      "\t Train accuracy:  0.19759679572763686\n",
      "\t Test accuracy:  0.164\n",
      "Training MLP layers: (100,), alpha: 0.1...\n",
      "\t Train accuracy:  0.1041388518024032\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (100,), alpha: 0.3...\n",
      "\t Train accuracy:  0.1081441922563418\n",
      "\t Test accuracy:  0.1\n",
      "Training MLP layers: (100,), alpha: 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Train accuracy:  0.17623497997329773\n",
      "\t Test accuracy:  0.168\n",
      "Training MLP layers: (100, 100), alpha: 0.0001...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.424\n",
      "Training MLP layers: (100, 100), alpha: 0.01...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.424\n",
      "Training MLP layers: (100, 100), alpha: 0.1...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.38\n",
      "Training MLP layers: (100, 100), alpha: 0.3...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.424\n",
      "Training MLP layers: (100, 100), alpha: 1...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.448\n",
      "Training MLP layers: (100, 100, 100), alpha: 0.0001...\n",
      "\t Train accuracy:  0.9813084112149533\n",
      "\t Test accuracy:  0.364\n",
      "Training MLP layers: (100, 100, 100), alpha: 0.01...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.424\n",
      "Training MLP layers: (100, 100, 100), alpha: 0.1...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.412\n",
      "Training MLP layers: (100, 100, 100), alpha: 0.3...\n",
      "\t Train accuracy:  0.9986648865153538\n",
      "\t Test accuracy:  0.408\n",
      "Training MLP layers: (100, 100, 100), alpha: 1...\n",
      "\t Train accuracy:  0.5527369826435247\n",
      "\t Test accuracy:  0.32\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "layers = [(25,), (25, 25), (25,25,25), (50,), (50,50), (50,50,50), (100,), (100,100), (100,100,100)]\n",
    "regul = [0.0001, 0.01, 0.1, 0.3, 1]\n",
    "for l in layers:\n",
    "    for r in regul:\n",
    "        print('Training MLP layers: {}, alpha: {}...'.format(l, r))\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=l, max_iter=300, alpha=r, activation='relu', solver='adam', random_state=42)\n",
    "\n",
    "        mlp.fit(X_train, y_train)\n",
    "\n",
    "        prediction = mlp.predict(X_test)\n",
    "        test_score = mlp.score(X_test, y_test)\n",
    "        train_score = mlp.score(X_train, y_train)\n",
    "\n",
    "        print('\\t Train accuracy: ', train_score)\n",
    "        print('\\t Test accuracy: ', test_score)\n",
    "\n",
    "        predictions.append(prediction)\n",
    "        test_scores.append(test_score)\n",
    "        train_scores.append(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
